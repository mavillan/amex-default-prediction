{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import numba\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel,delayed\n",
    "import time\n",
    "import re\n",
    "\n",
    "#from pandarallel import pandarallel\n",
    "#pandarallel.initialize(progress_bar=True, use_memory_fs=True)\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../utils\")\n",
    "from memory import reduce_mem_usage\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this datasets aggreates the features over the time dimension\n",
    "\n",
    "- takes as base this dataset: https://www.kaggle.com/datasets/raddar/amex-data-integer-dtypes-parquet-format\n",
    "- feat engineering from here: https://www.kaggle.com/code/huseyincot/amex-agg-data-how-it-created\n",
    "- lag features idea from here: https://www.kaggle.com/code/thedevastator/lag-features-are-all-you-need/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.njit()\n",
    "def compute_slope(x, y):\n",
    "    x_mean = x.mean()\n",
    "    y_mean = y.mean()\n",
    "    return np.sum((x-x_mean)*(y-y_mean)) / np.sum((x-x_mean)**2)\n",
    "\n",
    "def compute_slope_cols(df, customer_ID, num_features):\n",
    "    n = len(df)\n",
    "    if n > 2:\n",
    "        x = np.arange(n)\n",
    "        _df = df[num_features].fillna(method=\"ffill\", axis=0).fillna(method=\"bfill\", axis=0)\n",
    "        r = _df[num_features].apply(lambda y: compute_slope(x, y.values))\n",
    "        r = r.to_dict()\n",
    "    else:\n",
    "        r = df[num_features].apply(lambda y: 0)\n",
    "        r = r.to_dict()\n",
    "    r[\"customer_ID\"] = customer_ID\n",
    "    return r\n",
    "\n",
    "def mode_1st(x):\n",
    "    return x.value_counts().index[0]\n",
    "\n",
    "def mode_2nd(x):\n",
    "    try: return x.value_counts().index[1]\n",
    "    except: return -1 \n",
    "\n",
    "numba.njit()\n",
    "def compute_last_diff(array):\n",
    "    if len(array) <= 1:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return array[-1]-array[-2]\n",
    "    \n",
    "def compute_last_diff_series(df, col):\n",
    "    r = df.groupby(\"customer_ID\")[col].apply(lambda x: compute_last_diff(x.values))\n",
    "    r.name = f\"{r.name}_diff\"\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# references: \n",
    "# https://www.kaggle.com/code/huseyincot/amex-agg-data-how-it-created\n",
    "# https://www.kaggle.com/code/cdeotte/xgboost-starter-0-793\n",
    "# after pay feats: https://www.kaggle.com/code/jiweiliu/rapids-cudf-feature-engineering-xgb\n",
    "# other lag features: https://www.kaggle.com/code/ragnar123/amex-lgbm-dart-cv-0-7977\n",
    "\n",
    "def build_features(df):\n",
    "    \n",
    "    all_cols = [c for c in list(df.columns) if c not in ['customer_ID','S_2']]\n",
    "    cat_features = [\"B_30\",\"B_38\",\"D_114\",\"D_116\",\"D_117\",\"D_120\",\"D_126\",\"D_63\",\"D_64\",\"D_66\",\"D_68\"]\n",
    "    num_features = [col for col in all_cols if col not in cat_features]\n",
    "    \n",
    "    print(\"Computing 'after pay' features\")\n",
    "    tic = time.time()\n",
    "    for bcol in [f'B_{i}' for i in [11,14,17]]+['D_39','D_131']+[f'S_{i}' for i in [16,23]]:\n",
    "        for pcol in ['P_2','P_3']:\n",
    "            if bcol in df.columns:\n",
    "                df[f'{bcol}-{pcol}'] = df[bcol] - df[pcol]\n",
    "                num_features.append(f'{bcol}-{pcol}')\n",
    "    tac = time.time()\n",
    "    print(f\"Elapsed time: {(tac-tic)/60} min\\n\")\n",
    "    \n",
    "    print(\"Computing numerical aggregations\")\n",
    "    tic = time.time()\n",
    "    df_num_agg = df.groupby(\"customer_ID\")[num_features].agg(['first', 'mean', 'std', 'min', 'max', 'last'])\n",
    "    df_num_agg.columns = ['_'.join(x) for x in df_num_agg.columns]\n",
    "    tac = time.time()\n",
    "    print(f\"Elapsed time: {(tac-tic)/60} min\\n\")\n",
    "    \n",
    "    print(\"Computing lag features\")\n",
    "    for col in num_features:\n",
    "        df_num_agg[f\"{col}_diff_wfirst\"] = df_num_agg[f\"{col}_last\"] - df_num_agg[f\"{col}_first\"]\n",
    "        df_num_agg[f\"{col}_diff_wmean\"] = df_num_agg[f\"{col}_last\"] - df_num_agg[f\"{col}_mean\"]        \n",
    "\n",
    "    to_remove = list(filter(re.compile(\".*_first\").match, df_num_agg.columns))\n",
    "    df_num_agg.drop(to_remove, axis=1, inplace=True)\n",
    "    \n",
    "    print(\"Computing diff features\")\n",
    "    results = list()\n",
    "    with Parallel(n_jobs=-1) as parallel:\n",
    "            delayed_func = delayed(compute_last_diff_series)\n",
    "            results = parallel(\n",
    "                delayed_func(df, col) \n",
    "                for col in tqdm(num_features)\n",
    "            )\n",
    "    df_diff = pd.concat(results, axis=1)\n",
    "    \n",
    "    print(\"Computing categorical aggregations\")\n",
    "    tic = time.time()\n",
    "    df_cat_agg = df.groupby(\"customer_ID\")[cat_features].agg(['first', 'last', 'nunique'])\n",
    "    df_cat_agg.columns = ['_'.join(x) for x in df_cat_agg.columns]\n",
    "    tac = time.time()\n",
    "    print(f\"Elapsed time: {(tac-tic)/60} min\\n\")\n",
    "    \n",
    "    #print(\"Computing slope features\")\n",
    "    #tic = time.time()\n",
    "    #with Parallel(n_jobs=-1) as parallel:\n",
    "    #        delayed_func = delayed(compute_slope_cols)\n",
    "    #        results = parallel(\n",
    "    #            delayed_func(_df, customer_ID, num_features) \n",
    "    #            for customer_ID,_df in tqdm(df.groupby(\"customer_ID\"))\n",
    "    #        )\n",
    "    #slopes_df = pd.DataFrame(results).fillna(0).set_index(\"customer_ID\")\n",
    "    #slopes_df.columns = [f\"{col}_slope\" for col in slopes_df.columns]\n",
    "    #tac = time.time()\n",
    "    #print(f\"Elapsed time: {(tac-tic)/60} min\\n\")\n",
    "    \n",
    "    print(\"Building some other features\")\n",
    "    df_count = df.groupby([\"customer_ID\"])[\"S_2\"].count()\n",
    "    df_count = pd.DataFrame(df_count).rename({\"S_2\":\"S_2_steps\"}, axis=1)\n",
    "\n",
    "    all_dfs = [df_num_agg, df_diff, df_cat_agg, df_count]\n",
    "    df = pd.concat(all_dfs, axis=1)\n",
    "    del df_num_agg, df_cat_agg, df_count\n",
    "    gc.collect()\n",
    "\n",
    "    print('shape after engineering', df.shape )\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## preproc on train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_parquet(\"../data/ext/amex-data-integer-dtypes-parquet-format/train.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing 'after pay' features\n",
      "Elapsed time: 0.0025058587392171225 min\n",
      "\n",
      "Computing numerical aggregations\n",
      "Elapsed time: 1.2458173354466757 min\n",
      "\n",
      "Computing lag features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing diff features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 191/191 [05:53<00:00,  1.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing categorical aggregations\n",
      "Elapsed time: 0.12539454301198324 min\n",
      "\n",
      "Building some other features\n",
      "shape after engineering (458913, 1562)\n",
      "Mem. usage decreased to 2266.61 Mb (30.6% reduction)\n",
      "CPU times: user 5min 35s, sys: 1min 39s, total: 7min 15s\n",
      "Wall time: 9min 19s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "train_agg = build_features(train)\n",
    "train_agg = reduce_mem_usage(train_agg, verbose=True)\n",
    "train_agg.to_parquet(\"../data/processed/dsv02/train.parquet\")\n",
    "\n",
    "del train,train_agg\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## preproc on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = pd.read_parquet(\"../data/ext/amex-data-integer-dtypes-parquet-format/test.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing 'after pay' features\n",
      "Elapsed time: 0.00445781946182251 min\n",
      "\n",
      "Computing numerical aggregations\n",
      "Elapsed time: 2.5173694054285685 min\n",
      "\n",
      "Computing lag features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing diff features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 191/191 [12:03<00:00,  3.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing categorical aggregations\n",
      "Elapsed time: 0.22676137685775757 min\n",
      "\n",
      "Building some other features\n",
      "shape after engineering (924621, 1562)\n",
      "Mem. usage decreased to 4571.19 Mb (30.6% reduction)\n",
      "CPU times: user 11min 37s, sys: 3min 35s, total: 15min 13s\n",
      "Wall time: 18min 34s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "test_agg = build_features(test)\n",
    "test_agg = reduce_mem_usage(test_agg, verbose=True)\n",
    "test_agg.to_parquet(\"../data/processed/dsv02/test.parquet\")\n",
    "\n",
    "del test,test_agg\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
