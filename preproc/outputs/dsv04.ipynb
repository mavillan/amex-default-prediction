{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d80527c",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-07-18T23:46:21.046149Z",
     "iopub.status.busy": "2022-07-18T23:46:21.045645Z",
     "iopub.status.idle": "2022-07-18T23:46:21.610862Z",
     "shell.execute_reply": "2022-07-18T23:46:21.611362Z"
    },
    "papermill": {
     "duration": 0.587385,
     "end_time": "2022-07-18T23:46:21.611621",
     "exception": false,
     "start_time": "2022-07-18T23:46:21.024236",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import numba\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel,delayed\n",
    "import time\n",
    "import re\n",
    "\n",
    "import category_encoders as ce\n",
    "\n",
    "#from pandarallel import pandarallel\n",
    "#pandarallel.initialize(progress_bar=True, use_memory_fs=True)\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../utils\")\n",
    "from memory import reduce_mem_usage\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f4a86a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-18T23:46:21.636630Z",
     "iopub.status.busy": "2022-07-18T23:46:21.636135Z",
     "iopub.status.idle": "2022-07-18T23:46:21.638102Z",
     "shell.execute_reply": "2022-07-18T23:46:21.637711Z"
    },
    "papermill": {
     "duration": 0.015712,
     "end_time": "2022-07-18T23:46:21.638223",
     "exception": false,
     "start_time": "2022-07-18T23:46:21.622511",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "OUTPUT_PATH = Path(\"../data/processed/dsv04\")\n",
    "\n",
    "if not OUTPUT_PATH.exists():\n",
    "    OUTPUT_PATH.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288c7f28",
   "metadata": {
    "papermill": {
     "duration": 0.010138,
     "end_time": "2022-07-18T23:46:21.658511",
     "exception": false,
     "start_time": "2022-07-18T23:46:21.648373",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "this datasets aggreates the features over the time dimension\n",
    "\n",
    "- takes as base this dataset: https://www.kaggle.com/datasets/raddar/amex-data-integer-dtypes-parquet-format\n",
    "- feat engineering from here: https://www.kaggle.com/code/huseyincot/amex-agg-data-how-it-created\n",
    "- lag features idea from here: https://www.kaggle.com/code/thedevastator/lag-features-are-all-you-need/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39232e93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-18T23:46:21.687605Z",
     "iopub.status.busy": "2022-07-18T23:46:21.687101Z",
     "iopub.status.idle": "2022-07-18T23:46:21.712272Z",
     "shell.execute_reply": "2022-07-18T23:46:21.712631Z"
    },
    "papermill": {
     "duration": 0.044147,
     "end_time": "2022-07-18T23:46:21.712770",
     "exception": false,
     "start_time": "2022-07-18T23:46:21.668623",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@numba.njit()\n",
    "def compute_slope(x, y):\n",
    "    x_mean = x.mean()\n",
    "    y_mean = y.mean()\n",
    "    return np.sum((x-x_mean)*(y-y_mean)) / np.sum((x-x_mean)**2)\n",
    "\n",
    "def compute_slope_cols(df, customer_ID, num_features):\n",
    "    n = len(df)\n",
    "    if n > 2:\n",
    "        x = np.arange(n)\n",
    "        _df = df[num_features].fillna(method=\"ffill\", axis=0).fillna(method=\"bfill\", axis=0)\n",
    "        r = _df[num_features].apply(lambda y: compute_slope(x, y.values))\n",
    "        r = r.to_dict()\n",
    "    else:\n",
    "        r = df[num_features].apply(lambda y: 0)\n",
    "        r = r.to_dict()\n",
    "    r[\"customer_ID\"] = customer_ID\n",
    "    return r\n",
    "\n",
    "def mode_1st(x):\n",
    "    return x.value_counts().index[0]\n",
    "\n",
    "def mode_2nd(x):\n",
    "    try: return x.value_counts().index[1]\n",
    "    except: return -1 \n",
    "\n",
    "numba.njit()\n",
    "def compute_last_diff(array):\n",
    "    if len(array) <= 1:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return array[-1]-array[-2]\n",
    "    \n",
    "def compute_last_diff_series(df, col):\n",
    "    r = df.groupby(\"customer_ID\")[col].apply(lambda x: compute_last_diff(x.values))\n",
    "    r.name = f\"{r.name}_diff\"\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5101006",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-18T23:46:21.749466Z",
     "iopub.status.busy": "2022-07-18T23:46:21.748910Z",
     "iopub.status.idle": "2022-07-18T23:46:21.750985Z",
     "shell.execute_reply": "2022-07-18T23:46:21.750509Z"
    },
    "papermill": {
     "duration": 0.027766,
     "end_time": "2022-07-18T23:46:21.751102",
     "exception": false,
     "start_time": "2022-07-18T23:46:21.723336",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# references: \n",
    "# https://www.kaggle.com/code/huseyincot/amex-agg-data-how-it-created\n",
    "# https://www.kaggle.com/code/cdeotte/xgboost-starter-0-793\n",
    "# after pay feats: https://www.kaggle.com/code/jiweiliu/rapids-cudf-feature-engineering-xgb\n",
    "# other lag features: https://www.kaggle.com/code/ragnar123/amex-lgbm-dart-cv-0-7977\n",
    "\n",
    "def remove_noise(df): \n",
    "    # removes noise from float columns\n",
    "    float_cols = df.dtypes[df.dtypes == \"float32\"].index\n",
    "    print(f\"# of float cols to reduce noise: {len(float_cols)}\")\n",
    "    \n",
    "    for col in float_cols:\n",
    "        df[col] = df[col].round(decimals=2)\n",
    "        \n",
    "    return df\n",
    "\n",
    "def build_features(df, ohe_cols):\n",
    "    \n",
    "    all_cols = [c for c in list(df.columns) if c not in ['customer_ID','S_2']]\n",
    "    num_features = [col for col in all_cols if col not in ohe_cols]\n",
    "    \n",
    "    print(\"Computing 'after pay' features\")\n",
    "    tic = time.time()\n",
    "    for bcol in [f'B_{i}' for i in [11,14,17]]+['D_39','D_131']+[f'S_{i}' for i in [16,23]]:\n",
    "        for pcol in ['P_2','P_3']:\n",
    "            if bcol in df.columns:\n",
    "                df[f'{bcol}-{pcol}'] = df[bcol] - df[pcol]\n",
    "                num_features.append(f'{bcol}-{pcol}')\n",
    "    tac = time.time()\n",
    "    print(f\"Elapsed time: {(tac-tic)/60} min\\n\")\n",
    "    \n",
    "    print(\"Computing numerical aggregations\")\n",
    "    tic = time.time()\n",
    "    df_num_agg = df.groupby(\"customer_ID\")[num_features].agg(['first', 'mean', 'std', 'min', 'max', 'last'])\n",
    "    df_num_agg.columns = ['_'.join(x) for x in df_num_agg.columns]\n",
    "    tac = time.time()\n",
    "    print(f\"Elapsed time: {(tac-tic)/60} min\\n\")\n",
    "    \n",
    "    print(\"Computing lag features\")\n",
    "    for col in num_features:\n",
    "        df_num_agg[f\"{col}_diff_wfirst\"] = df_num_agg[f\"{col}_last\"] - df_num_agg[f\"{col}_first\"]\n",
    "        df_num_agg[f\"{col}_diff_wmean\"] = df_num_agg[f\"{col}_last\"] - df_num_agg[f\"{col}_mean\"]        \n",
    "\n",
    "    to_remove = list(filter(re.compile(\".*_first\").match, df_num_agg.columns))\n",
    "    df_num_agg.drop(to_remove, axis=1, inplace=True)\n",
    "    \n",
    "    print(\"Computing diff features\")\n",
    "    results = list()\n",
    "    with Parallel(n_jobs=-1) as parallel:\n",
    "            delayed_func = delayed(compute_last_diff_series)\n",
    "            results = parallel(\n",
    "                delayed_func(df, col) \n",
    "                for col in tqdm(num_features)\n",
    "            )\n",
    "    df_diff = pd.concat(results, axis=1)\n",
    "    \n",
    "    print(\"Computing categorical aggregations\")\n",
    "    tic = time.time()\n",
    "    df_cat_agg1 = (\n",
    "        df\n",
    "        .groupby(\"customer_ID\")\n",
    "        [ohe_cols]\n",
    "        .mean()\n",
    "    )\n",
    "    df_cat_agg1.columns = [col+\"_\"+\"mean\" for col in df_cat_agg1.columns]\n",
    "    df_cat_agg2 = (\n",
    "        df\n",
    "        .groupby(\"customer_ID\")\n",
    "        [ohe_cols]\n",
    "        .agg(compute_last_observed)\n",
    "    )\n",
    "    df_cat_agg2.columns = [col+\"_\"+\"lo\" for col in df_cat_agg2.columns]\n",
    "    \n",
    "    tac = time.time()\n",
    "    print(f\"Elapsed time: {(tac-tic)/60} min\\n\")\n",
    "    \n",
    "    #print(\"Computing slope features\")\n",
    "    #tic = time.time()\n",
    "    #with Parallel(n_jobs=-1) as parallel:\n",
    "    #        delayed_func = delayed(compute_slope_cols)\n",
    "    #        results = parallel(\n",
    "    #            delayed_func(_df, customer_ID, num_features) \n",
    "    #            for customer_ID,_df in tqdm(df.groupby(\"customer_ID\"))\n",
    "    #        )\n",
    "    #slopes_df = pd.DataFrame(results).fillna(0).set_index(\"customer_ID\")\n",
    "    #slopes_df.columns = [f\"{col}_slope\" for col in slopes_df.columns]\n",
    "    #tac = time.time()\n",
    "    #print(f\"Elapsed time: {(tac-tic)/60} min\\n\")\n",
    "    \n",
    "    print(\"Building S_2 related features\")\n",
    "    tic = time.time()\n",
    "    df_count = df.groupby([\"customer_ID\"])[\"S_2\"].count()\n",
    "    df_count = pd.DataFrame(df_count).rename({\"S_2\":\"S_2_steps\"}, axis=1)\n",
    "    tac = time.time()\n",
    "    print(f\"Elapsed time: {(tac-tic)/60} min\\n\")\n",
    "\n",
    "    print(\"Concatenating all the results\")\n",
    "    tic = time.time()\n",
    "    all_dfs = [df_num_agg, df_diff, df_cat_agg1, df_cat_agg2, df_count]\n",
    "    df = pd.concat(all_dfs, axis=1)\n",
    "    tac = time.time()\n",
    "    print(f\"Elapsed time: {(tac-tic)/60} min\\n\")\n",
    "    \n",
    "    del df_num_agg, df_diff, df_cat_agg1, df_cat_agg2, df_count\n",
    "    gc.collect()\n",
    "\n",
    "    print('shape after engineering', df.shape )\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffb0aa24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-18T23:46:21.778236Z",
     "iopub.status.busy": "2022-07-18T23:46:21.777740Z",
     "iopub.status.idle": "2022-07-18T23:46:21.779337Z",
     "shell.execute_reply": "2022-07-18T23:46:21.779715Z"
    },
    "papermill": {
     "duration": 0.018076,
     "end_time": "2022-07-18T23:46:21.779836",
     "exception": false,
     "start_time": "2022-07-18T23:46:21.761760",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def encode_categoricals(dataframe, encoder=None):\n",
    "    categoricals = [\n",
    "        'B_30', 'B_38', 'D_63', 'D_64', 'D_66', 'D_68', \n",
    "        'D_114', 'D_116', 'D_117', 'D_120', 'D_126',\n",
    "    ]\n",
    "    \n",
    "    if encoder is None:\n",
    "        print(\"fitting the encoder\")\n",
    "        encoder = ce.one_hot.OneHotEncoder(cols=categoricals)\n",
    "        encoder.fit(dataframe[categoricals])\n",
    "        \n",
    "    out = encoder.transform(dataframe[categoricals]).astype(np.int8)\n",
    "    ohe_cols = encoder.get_feature_names()\n",
    "    \n",
    "    dataframe.drop(categoricals, axis=1, inplace=True)\n",
    "    dataframe = pd.concat([dataframe, out], axis=1)\n",
    "\n",
    "    gc.collect()\n",
    "    \n",
    "    return dataframe, encoder, ohe_cols\n",
    "\n",
    "#@numba.njit()\n",
    "def compute_last_observed(series):\n",
    "    idx = np.nonzero(series.values[::-1])[0]\n",
    "    if len(idx)==0:\n",
    "        return 100\n",
    "    else:\n",
    "        return idx[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00b2aa7",
   "metadata": {
    "papermill": {
     "duration": 0.010395,
     "end_time": "2022-07-18T23:46:21.800689",
     "exception": false,
     "start_time": "2022-07-18T23:46:21.790294",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "***\n",
    "## preproc on train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e828e561",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-18T23:46:21.824872Z",
     "iopub.status.busy": "2022-07-18T23:46:21.824399Z",
     "iopub.status.idle": "2022-07-18T23:46:21.825970Z",
     "shell.execute_reply": "2022-07-18T23:46:21.826345Z"
    },
    "papermill": {
     "duration": 0.015371,
     "end_time": "2022-07-18T23:46:21.826472",
     "exception": false,
     "start_time": "2022-07-18T23:46:21.811101",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train[\"S_2\"] = pd.to_datetime(train.S_2)\n",
    "#train[\"year\"] = train.S_2.dt.year\n",
    "#train[\"month\"] = train.S_2.dt.month\n",
    "\n",
    "#train[\"year_month\"] = train.year.astype(str) + \"-\" + train.month.astype(str)\n",
    "\n",
    "#cid = train.sample()[\"customer_ID\"].values[0]\n",
    "#df = train.query(\"customer_ID == @cid\")\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1499826c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-18T23:46:21.850437Z",
     "iopub.status.busy": "2022-07-18T23:46:21.849946Z",
     "iopub.status.idle": "2022-07-18T23:46:21.851543Z",
     "shell.execute_reply": "2022-07-18T23:46:21.851896Z"
    },
    "papermill": {
     "duration": 0.014869,
     "end_time": "2022-07-18T23:46:21.852015",
     "exception": false,
     "start_time": "2022-07-18T23:46:21.837146",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#def diff_month(d1, d2):\n",
    "#    return (d1.year - d2.year) * 12 + d1.month - d2.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50402d70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-18T23:46:21.876155Z",
     "iopub.status.busy": "2022-07-18T23:46:21.875678Z",
     "iopub.status.idle": "2022-07-18T23:46:21.877288Z",
     "shell.execute_reply": "2022-07-18T23:46:21.877638Z"
    },
    "papermill": {
     "duration": 0.015134,
     "end_time": "2022-07-18T23:46:21.877756",
     "exception": false,
     "start_time": "2022-07-18T23:46:21.862622",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#def compute_antiquity(df):\n",
    "#    return (df.S_2.dt.year.values[-1] - df.S_2.dt.year.values[0])*12 + (df.S_2.dt.month.values[-1] - df.S_2.dt.month.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "066c8970",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-18T23:46:21.901951Z",
     "iopub.status.busy": "2022-07-18T23:46:21.901487Z",
     "iopub.status.idle": "2022-07-18T23:46:21.903106Z",
     "shell.execute_reply": "2022-07-18T23:46:21.903469Z"
    },
    "papermill": {
     "duration": 0.015099,
     "end_time": "2022-07-18T23:46:21.903588",
     "exception": false,
     "start_time": "2022-07-18T23:46:21.888489",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "#r1 = train.groupby(\"customer_ID\").apply(compute_antiquity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab416223",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-18T23:46:21.927730Z",
     "iopub.status.busy": "2022-07-18T23:46:21.927269Z",
     "iopub.status.idle": "2022-07-18T23:46:21.929388Z",
     "shell.execute_reply": "2022-07-18T23:46:21.928954Z"
    },
    "papermill": {
     "duration": 0.01517,
     "end_time": "2022-07-18T23:46:21.929490",
     "exception": false,
     "start_time": "2022-07-18T23:46:21.914320",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "#r2 = train.groupby(\"customer_ID\")[\"S_2\"].apply(lambda x: x.diff().max().days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09a14c2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-18T23:46:21.954585Z",
     "iopub.status.busy": "2022-07-18T23:46:21.954104Z",
     "iopub.status.idle": "2022-07-18T23:46:21.955663Z",
     "shell.execute_reply": "2022-07-18T23:46:21.956006Z"
    },
    "papermill": {
     "duration": 0.015594,
     "end_time": "2022-07-18T23:46:21.956142",
     "exception": false,
     "start_time": "2022-07-18T23:46:21.940548",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#r1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80c0cbfa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-18T23:46:21.981137Z",
     "iopub.status.busy": "2022-07-18T23:46:21.980665Z",
     "iopub.status.idle": "2022-07-18T23:46:21.982305Z",
     "shell.execute_reply": "2022-07-18T23:46:21.982655Z"
    },
    "papermill": {
     "duration": 0.015672,
     "end_time": "2022-07-18T23:46:21.982776",
     "exception": false,
     "start_time": "2022-07-18T23:46:21.967104",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#r2.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b0ec91",
   "metadata": {
    "papermill": {
     "duration": 0.011028,
     "end_time": "2022-07-18T23:46:22.004871",
     "exception": false,
     "start_time": "2022-07-18T23:46:21.993843",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da8c253d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-18T23:46:22.030920Z",
     "iopub.status.busy": "2022-07-18T23:46:22.030435Z",
     "iopub.status.idle": "2022-07-18T23:46:35.264385Z",
     "shell.execute_reply": "2022-07-18T23:46:35.263969Z"
    },
    "papermill": {
     "duration": 13.248557,
     "end_time": "2022-07-18T23:46:35.264506",
     "exception": false,
     "start_time": "2022-07-18T23:46:22.015949",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5531451 entries, 0 to 5531450\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: float32(93), int16(9), int8(86), object(2)\n",
      "memory usage: 2.5+ GB\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_parquet(\"../data/ext/amex-data-integer-dtypes-parquet-format/train.parquet\")\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec89ef94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-18T23:46:35.293450Z",
     "iopub.status.busy": "2022-07-18T23:46:35.292941Z",
     "iopub.status.idle": "2022-07-18T23:55:40.705463Z",
     "shell.execute_reply": "2022-07-18T23:55:40.705003Z"
    },
    "papermill": {
     "duration": 545.428899,
     "end_time": "2022-07-18T23:55:40.705579",
     "exception": false,
     "start_time": "2022-07-18T23:46:35.276680",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of float cols to reduce noise: 93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting the encoder\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing 'after pay' features\n",
      "Elapsed time: 0.0021482110023498535 min\n",
      "\n",
      "Computing numerical aggregations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 1.1426782290140787 min\n",
      "\n",
      "Computing lag features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:42: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing diff features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                | 0/191 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|████▌                                                  | 16/191 [00:00<00:07, 22.99it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|████▌                                                  | 16/191 [00:10<00:07, 22.99it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█████████▏                                             | 32/191 [00:13<01:16,  2.07it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|█████████████▊                                         | 48/191 [00:31<01:53,  1.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██████████████                                         | 49/191 [00:32<01:52,  1.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|██████████████████▍                                    | 64/191 [00:50<02:04,  1.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|██████████████████▋                                    | 65/191 [00:51<02:01,  1.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|███████████████████████                                | 80/191 [01:09<01:57,  1.06s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|███████████████████████▎                               | 81/191 [01:09<01:55,  1.05s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|███████████████████████████▋                           | 96/191 [01:27<01:45,  1.11s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|███████████████████████████████▋                      | 112/191 [01:45<01:29,  1.13s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|████████████████████████████████████▏                 | 128/191 [02:04<01:12,  1.15s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|████████████████████████████████████████▋             | 144/191 [02:22<00:53,  1.13s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|█████████████████████████████████████████████▏        | 160/191 [02:40<00:35,  1.14s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████████████████████████████████████████████▊    | 176/191 [02:59<00:17,  1.15s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████████████████████████████████████████████████| 191/191 [02:59<00:00,  1.06it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing categorical aggregations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 2.499083971977234 min\n",
      "\n",
      "Building S_2 related features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 0.018985867500305176 min\n",
      "\n",
      "Concatenating all the results\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 0.05188761949539185 min\n",
      "\n",
      "shape after engineering (458913, 1639)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 2372.52 Mb (34.2% reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 29s, sys: 1min 35s, total: 9min 5s\n",
      "Wall time: 9min 5s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "train = remove_noise(train)\n",
    "train, encoder, ohe_cols = encode_categoricals(train)\n",
    "train_agg = build_features(train, ohe_cols)\n",
    "train_agg = reduce_mem_usage(train_agg, verbose=True)\n",
    "train_agg.to_parquet(str(OUTPUT_PATH/\"train.parquet\"))\n",
    "\n",
    "del train,train_agg\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04867f4",
   "metadata": {
    "papermill": {
     "duration": 0.018695,
     "end_time": "2022-07-18T23:55:40.743281",
     "exception": false,
     "start_time": "2022-07-18T23:55:40.724586",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "***\n",
    "## preproc on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7e668f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-18T23:55:40.780816Z",
     "iopub.status.busy": "2022-07-18T23:55:40.780319Z",
     "iopub.status.idle": "2022-07-18T23:56:06.299632Z",
     "shell.execute_reply": "2022-07-18T23:56:06.299992Z"
    },
    "papermill": {
     "duration": 25.538758,
     "end_time": "2022-07-18T23:56:06.300152",
     "exception": false,
     "start_time": "2022-07-18T23:55:40.761394",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11363762 entries, 0 to 11363761\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: float32(93), int16(10), int8(85), object(2)\n",
      "memory usage: 5.2+ GB\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_parquet(\"../data/ext/amex-data-integer-dtypes-parquet-format/test.parquet\")\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b34f9300",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-18T23:56:06.343481Z",
     "iopub.status.busy": "2022-07-18T23:56:06.342973Z",
     "iopub.status.idle": "2022-07-19T00:13:36.904675Z",
     "shell.execute_reply": "2022-07-19T00:13:36.904201Z"
    },
    "papermill": {
     "duration": 1050.585204,
     "end_time": "2022-07-19T00:13:36.904796",
     "exception": false,
     "start_time": "2022-07-18T23:56:06.319592",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of float cols to reduce noise: 93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing 'after pay' features\n",
      "Elapsed time: 0.003075726826985677 min\n",
      "\n",
      "Computing numerical aggregations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 2.0954121311505634 min\n",
      "\n",
      "Computing lag features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:42: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing diff features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                | 0/191 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|████▌                                                  | 16/191 [00:01<00:15, 11.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|████▌                                                  | 16/191 [00:17<00:15, 11.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█████████▏                                             | 32/191 [00:27<02:36,  1.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█████████▌                                             | 33/191 [00:29<02:42,  1.03s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|█████████████▊                                         | 48/191 [01:13<04:48,  2.02s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|██████████████████▍                                    | 64/191 [01:50<04:32,  2.15s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|███████████████████████                                | 80/191 [02:27<04:07,  2.23s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|███████████████████████▎                               | 81/191 [02:29<04:02,  2.20s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|███████████████████████████▋                           | 96/191 [03:05<03:36,  2.28s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|███████████████████████████████▋                      | 112/191 [03:41<02:59,  2.27s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|███████████████████████████████▉                      | 113/191 [03:42<02:55,  2.25s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|████████████████████████████████████▏                 | 128/191 [04:20<02:27,  2.35s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|████████████████████████████████████████▋             | 144/191 [04:58<01:50,  2.36s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|█████████████████████████████████████████████▏        | 160/191 [05:36<01:13,  2.36s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|█████████████████████████████████████████████▌        | 161/191 [05:36<01:08,  2.29s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████████████████████████████████████████████▊    | 176/191 [06:12<00:35,  2.34s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|██████████████████████████████████████████████████    | 177/191 [06:13<00:32,  2.31s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████████████████████████████████████████████████| 191/191 [06:13<00:00,  1.96s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing categorical aggregations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 5.0850771029790245 min\n",
      "\n",
      "Building S_2 related features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 0.03945449193318685 min\n",
      "\n",
      "Concatenating all the results\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 0.10026818116505941 min\n",
      "\n",
      "shape after engineering (924621, 1639)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 4784.58 Mb (34.2% reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14min 33s, sys: 3min 10s, total: 17min 43s\n",
      "Wall time: 17min 30s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "test = remove_noise(test)\n",
    "test, _, _ = encode_categoricals(test, encoder)\n",
    "test_agg = build_features(test, ohe_cols)\n",
    "test_agg = reduce_mem_usage(test_agg, verbose=True)\n",
    "test_agg.to_parquet(str(OUTPUT_PATH/\"test.parquet\"))\n",
    "\n",
    "del test,test_agg\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8b16f8",
   "metadata": {
    "papermill": {
     "duration": 0.171917,
     "end_time": "2022-07-19T00:13:37.241878",
     "exception": false,
     "start_time": "2022-07-19T00:13:37.069961",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1642.290505,
   "end_time": "2022-07-19T00:13:38.218530",
   "environment_variables": {},
   "exception": null,
   "input_path": "preproc/dsv04.ipynb",
   "output_path": "preproc/outputs/dsv04.ipynb",
   "parameters": {},
   "start_time": "2022-07-18T23:46:15.928025",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}