{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26d019f3",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-07-12T23:26:41.311104Z",
     "iopub.status.busy": "2022-07-12T23:26:41.310519Z",
     "iopub.status.idle": "2022-07-12T23:26:42.552318Z",
     "shell.execute_reply": "2022-07-12T23:26:42.552758Z"
    },
    "papermill": {
     "duration": 1.257943,
     "end_time": "2022-07-12T23:26:42.553052",
     "exception": false,
     "start_time": "2022-07-12T23:26:41.295109",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import numba\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel,delayed\n",
    "import time\n",
    "import re\n",
    "\n",
    "#from pandarallel import pandarallel\n",
    "#pandarallel.initialize(progress_bar=True, use_memory_fs=True)\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../utils\")\n",
    "from memory import reduce_mem_usage\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68dcd6c3",
   "metadata": {
    "papermill": {
     "duration": 0.005224,
     "end_time": "2022-07-12T23:26:42.565039",
     "exception": false,
     "start_time": "2022-07-12T23:26:42.559815",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "this datasets aggreates the features over the time dimension\n",
    "\n",
    "- takes as base this dataset: https://www.kaggle.com/datasets/raddar/amex-data-integer-dtypes-parquet-format\n",
    "- feat engineering from here: https://www.kaggle.com/code/huseyincot/amex-agg-data-how-it-created\n",
    "- lag features idea from here: https://www.kaggle.com/code/thedevastator/lag-features-are-all-you-need/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8eaa526",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-12T23:26:42.586816Z",
     "iopub.status.busy": "2022-07-12T23:26:42.583869Z",
     "iopub.status.idle": "2022-07-12T23:26:42.803878Z",
     "shell.execute_reply": "2022-07-12T23:26:42.803401Z"
    },
    "papermill": {
     "duration": 0.234039,
     "end_time": "2022-07-12T23:26:42.804033",
     "exception": false,
     "start_time": "2022-07-12T23:26:42.569994",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@numba.njit()\n",
    "def compute_slope(x, y):\n",
    "    x_mean = x.mean()\n",
    "    y_mean = y.mean()\n",
    "    return np.sum((x-x_mean)*(y-y_mean)) / np.sum((x-x_mean)**2)\n",
    "\n",
    "def compute_slope_cols(df, customer_ID, num_features):\n",
    "    n = len(df)\n",
    "    if n > 2:\n",
    "        x = np.arange(n)\n",
    "        _df = df[num_features].fillna(method=\"ffill\", axis=0).fillna(method=\"bfill\", axis=0)\n",
    "        r = _df[num_features].apply(lambda y: compute_slope(x, y.values))\n",
    "        r = r.to_dict()\n",
    "    else:\n",
    "        r = df[num_features].apply(lambda y: 0)\n",
    "        r = r.to_dict()\n",
    "    r[\"customer_ID\"] = customer_ID\n",
    "    return r\n",
    "\n",
    "def mode_1st(x):\n",
    "    return x.value_counts().index[0]\n",
    "\n",
    "def mode_2nd(x):\n",
    "    try: return x.value_counts().index[1]\n",
    "    except: return -1 \n",
    "\n",
    "numba.njit()\n",
    "def compute_last_diff(array):\n",
    "    if len(array) <= 1:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return array[-1]-array[-2]\n",
    "    \n",
    "def compute_last_diff_series(df, col):\n",
    "    r = df.groupby(\"customer_ID\")[col].apply(lambda x: compute_last_diff(x.values))\n",
    "    r.name = f\"{r.name}_diff\"\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdf265d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-12T23:26:42.833331Z",
     "iopub.status.busy": "2022-07-12T23:26:42.832687Z",
     "iopub.status.idle": "2022-07-12T23:26:42.834366Z",
     "shell.execute_reply": "2022-07-12T23:26:42.834725Z"
    },
    "papermill": {
     "duration": 0.024389,
     "end_time": "2022-07-12T23:26:42.834875",
     "exception": false,
     "start_time": "2022-07-12T23:26:42.810486",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# references: \n",
    "# https://www.kaggle.com/code/huseyincot/amex-agg-data-how-it-created\n",
    "# https://www.kaggle.com/code/cdeotte/xgboost-starter-0-793\n",
    "# after pay feats: https://www.kaggle.com/code/jiweiliu/rapids-cudf-feature-engineering-xgb\n",
    "# other lag features: https://www.kaggle.com/code/ragnar123/amex-lgbm-dart-cv-0-7977\n",
    "\n",
    "def remove_noise(df): \n",
    "    # removes noise from float columns\n",
    "    float_cols = df.dtypes[df.dtypes == \"float32\"].index\n",
    "    print(f\"# of float cols to reduce noise: {len(float_cols)}\")\n",
    "    \n",
    "    for col in float_cols:\n",
    "        df[col] = df[col].round(decimals=2)\n",
    "        \n",
    "    return df\n",
    "\n",
    "def build_features(df):\n",
    "    \n",
    "    all_cols = [c for c in list(df.columns) if c not in ['customer_ID','S_2']]\n",
    "    cat_features = [\"B_30\",\"B_38\",\"D_114\",\"D_116\",\"D_117\",\"D_120\",\"D_126\",\"D_63\",\"D_64\",\"D_66\",\"D_68\"]\n",
    "    num_features = [col for col in all_cols if col not in cat_features]\n",
    "    \n",
    "    print(\"Computing 'after pay' features\")\n",
    "    tic = time.time()\n",
    "    for bcol in [f'B_{i}' for i in [11,14,17]]+['D_39','D_131']+[f'S_{i}' for i in [16,23]]:\n",
    "        for pcol in ['P_2','P_3']:\n",
    "            if bcol in df.columns:\n",
    "                df[f'{bcol}-{pcol}'] = df[bcol] - df[pcol]\n",
    "                num_features.append(f'{bcol}-{pcol}')\n",
    "    tac = time.time()\n",
    "    print(f\"Elapsed time: {(tac-tic)/60} min\\n\")\n",
    "    \n",
    "    print(\"Computing numerical aggregations\")\n",
    "    tic = time.time()\n",
    "    df_num_agg = df.groupby(\"customer_ID\")[num_features].agg(['first', 'mean', 'std', 'min', 'max', 'last'])\n",
    "    df_num_agg.columns = ['_'.join(x) for x in df_num_agg.columns]\n",
    "    tac = time.time()\n",
    "    print(f\"Elapsed time: {(tac-tic)/60} min\\n\")\n",
    "    \n",
    "    print(\"Computing lag features\")\n",
    "    for col in num_features:\n",
    "        df_num_agg[f\"{col}_diff_wfirst\"] = df_num_agg[f\"{col}_last\"] - df_num_agg[f\"{col}_first\"]\n",
    "        df_num_agg[f\"{col}_diff_wmean\"] = df_num_agg[f\"{col}_last\"] - df_num_agg[f\"{col}_mean\"]        \n",
    "\n",
    "    to_remove = list(filter(re.compile(\".*_first\").match, df_num_agg.columns))\n",
    "    df_num_agg.drop(to_remove, axis=1, inplace=True)\n",
    "    \n",
    "    print(\"Computing diff features\")\n",
    "    results = list()\n",
    "    with Parallel(n_jobs=-1) as parallel:\n",
    "            delayed_func = delayed(compute_last_diff_series)\n",
    "            results = parallel(\n",
    "                delayed_func(df, col) \n",
    "                for col in tqdm(num_features)\n",
    "            )\n",
    "    df_diff = pd.concat(results, axis=1)\n",
    "    \n",
    "    print(\"Computing categorical aggregations\")\n",
    "    tic = time.time()\n",
    "    df_cat_agg = df.groupby(\"customer_ID\")[cat_features].agg(['first', 'last', 'nunique'])\n",
    "    df_cat_agg.columns = ['_'.join(x) for x in df_cat_agg.columns]\n",
    "    tac = time.time()\n",
    "    print(f\"Elapsed time: {(tac-tic)/60} min\\n\")\n",
    "    \n",
    "    #print(\"Computing slope features\")\n",
    "    #tic = time.time()\n",
    "    #with Parallel(n_jobs=-1) as parallel:\n",
    "    #        delayed_func = delayed(compute_slope_cols)\n",
    "    #        results = parallel(\n",
    "    #            delayed_func(_df, customer_ID, num_features) \n",
    "    #            for customer_ID,_df in tqdm(df.groupby(\"customer_ID\"))\n",
    "    #        )\n",
    "    #slopes_df = pd.DataFrame(results).fillna(0).set_index(\"customer_ID\")\n",
    "    #slopes_df.columns = [f\"{col}_slope\" for col in slopes_df.columns]\n",
    "    #tac = time.time()\n",
    "    #print(f\"Elapsed time: {(tac-tic)/60} min\\n\")\n",
    "    \n",
    "    print(\"Building some other features\")\n",
    "    df_count = df.groupby([\"customer_ID\"])[\"S_2\"].count()\n",
    "    df_count = pd.DataFrame(df_count).rename({\"S_2\":\"S_2_steps\"}, axis=1)\n",
    "\n",
    "    all_dfs = [df_num_agg, df_diff, df_cat_agg, df_count]\n",
    "    df = pd.concat(all_dfs, axis=1)\n",
    "    del df_num_agg, df_cat_agg, df_count\n",
    "    gc.collect()\n",
    "\n",
    "    print('shape after engineering', df.shape )\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd98b5c",
   "metadata": {
    "papermill": {
     "duration": 0.006288,
     "end_time": "2022-07-12T23:26:42.847391",
     "exception": false,
     "start_time": "2022-07-12T23:26:42.841103",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "***\n",
    "## preproc on train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99fd9f6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-12T23:26:42.866553Z",
     "iopub.status.busy": "2022-07-12T23:26:42.865930Z",
     "iopub.status.idle": "2022-07-12T23:26:56.332553Z",
     "shell.execute_reply": "2022-07-12T23:26:56.332109Z"
    },
    "papermill": {
     "duration": 13.476916,
     "end_time": "2022-07-12T23:26:56.332680",
     "exception": false,
     "start_time": "2022-07-12T23:26:42.855764",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_parquet(\"../data/ext/amex-data-integer-dtypes-parquet-format/train.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6131632e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-12T23:26:56.355828Z",
     "iopub.status.busy": "2022-07-12T23:26:56.355270Z",
     "iopub.status.idle": "2022-07-12T23:33:13.071932Z",
     "shell.execute_reply": "2022-07-12T23:33:13.072326Z"
    },
    "papermill": {
     "duration": 376.733144,
     "end_time": "2022-07-12T23:33:13.072483",
     "exception": false,
     "start_time": "2022-07-12T23:26:56.339339",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of float cols to reduce noise: 93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing 'after pay' features\n",
      "Elapsed time: 0.002342379093170166 min\n",
      "\n",
      "Computing numerical aggregations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 1.1875055074691772 min\n",
      "\n",
      "Computing lag features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:42: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing diff features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                | 0/191 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|████▌                                                  | 16/191 [00:00<00:06, 27.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█████████▏                                             | 32/191 [00:14<01:21,  1.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|█████████████▊                                         | 48/191 [00:33<01:59,  1.20it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██████████████                                         | 49/191 [00:34<01:57,  1.20it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██████████████                                         | 49/191 [00:51<01:57,  1.20it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|██████████████████▍                                    | 64/191 [00:52<02:06,  1.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|██████████████████▋                                    | 65/191 [00:52<02:04,  1.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|███████████████████████                                | 80/191 [01:10<01:58,  1.07s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|███████████████████████████▋                           | 96/191 [01:29<01:46,  1.12s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|███████████████████████████▉                           | 97/191 [01:30<01:44,  1.12s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|███████████████████████████████▋                      | 112/191 [01:47<01:28,  1.12s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|███████████████████████████████▉                      | 113/191 [01:48<01:27,  1.12s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|████████████████████████████████████▏                 | 128/191 [02:06<01:12,  1.15s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|████████████████████████████████████▍                 | 129/191 [02:06<01:10,  1.13s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|████████████████████████████████████████▋             | 144/191 [02:25<00:54,  1.17s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|█████████████████████████████████████████████▏        | 160/191 [02:43<00:35,  1.15s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|█████████████████████████████████████████████▌        | 161/191 [02:43<00:33,  1.13s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████████████████████████████████████████████▊    | 176/191 [03:02<00:17,  1.17s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|██████████████████████████████████████████████████    | 177/191 [03:02<00:16,  1.16s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████████████████████████████████████████████████| 191/191 [03:02<00:00,  1.04it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing categorical aggregations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 0.10243608951568603 min\n",
      "\n",
      "Building some other features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape after engineering (458913, 1562)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 2266.61 Mb (30.6% reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 43s, sys: 1min 34s, total: 6min 18s\n",
      "Wall time: 6min 16s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "train = remove_noise(train)\n",
    "train_agg = build_features(train)\n",
    "train_agg = reduce_mem_usage(train_agg, verbose=True)\n",
    "train_agg.to_parquet(\"../data/processed/dsv02/train.parquet\")\n",
    "\n",
    "del train,train_agg\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bd41e5",
   "metadata": {
    "papermill": {
     "duration": 0.013959,
     "end_time": "2022-07-12T23:33:13.100840",
     "exception": false,
     "start_time": "2022-07-12T23:33:13.086881",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "***\n",
    "## preproc on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5ee4f8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-12T23:33:13.133294Z",
     "iopub.status.busy": "2022-07-12T23:33:13.132751Z",
     "iopub.status.idle": "2022-07-12T23:33:38.651526Z",
     "shell.execute_reply": "2022-07-12T23:33:38.651073Z"
    },
    "papermill": {
     "duration": 25.536864,
     "end_time": "2022-07-12T23:33:38.651654",
     "exception": false,
     "start_time": "2022-07-12T23:33:13.114790",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = pd.read_parquet(\"../data/ext/amex-data-integer-dtypes-parquet-format/test.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "941580fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-12T23:33:38.681633Z",
     "iopub.status.busy": "2022-07-12T23:33:38.679023Z"
    },
    "papermill": {
     "duration": 498.836206,
     "end_time": "2022-07-12T23:41:57.501293",
     "exception": false,
     "start_time": "2022-07-12T23:33:38.665087",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of float cols to reduce noise: 93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing 'after pay' features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 0.0033964673678080243 min\n",
      "\n",
      "Computing numerical aggregations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 2.281154465675354 min\n",
      "\n",
      "Computing lag features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:42: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing diff features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                | 0/191 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█████████▏                                             | 32/191 [00:34<02:50,  1.07s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|█████████████▊                                         | 48/191 [01:16<04:07,  1.73s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██████████████                                         | 49/191 [01:18<04:05,  1.73s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|██████████████████▍                                    | 64/191 [01:56<04:25,  2.09s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|███████████████████████                                | 80/191 [02:34<04:04,  2.21s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|███████████████████████▎                               | 81/191 [02:36<04:00,  2.18s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|███████████████████████████▋                           | 96/191 [03:13<03:37,  2.29s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|███████████████████████████▉                           | 97/191 [03:14<03:32,  2.26s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|███████████████████████████████▋                      | 112/191 [03:51<03:05,  2.35s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|███████████████████████████████▉                      | 113/191 [03:52<03:00,  2.32s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|████████████████████████████████▏                     | 114/191 [03:53<02:49,  2.20s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|████████████████████████████████████▏                 | 128/191 [04:29<02:32,  2.42s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|████████████████████████████████████▍                 | 129/191 [04:31<02:26,  2.37s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|████████████████████████████████████████▋             | 144/191 [05:07<01:52,  2.39s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|█████████████████████████████████████████████▏        | 160/191 [05:45<01:13,  2.38s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|█████████████████████████████████████████████▌        | 161/191 [05:47<01:10,  2.37s/it]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test = remove_noise(test)\n",
    "test_agg = build_features(test)\n",
    "test_agg = reduce_mem_usage(test_agg, verbose=True)\n",
    "test_agg.to_parquet(\"../data/processed/dsv02/test.parquet\")\n",
    "\n",
    "del test,test_agg\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297a2f15",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 921.773268,
   "end_time": "2022-07-12T23:41:57.572600",
   "environment_variables": {},
   "exception": null,
   "input_path": "preproc/dsv02.ipynb",
   "output_path": "preproc/outputs/dsv02.ipynb",
   "parameters": {},
   "start_time": "2022-07-12T23:26:35.799332",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}