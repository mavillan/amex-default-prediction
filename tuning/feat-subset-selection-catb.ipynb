{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfc1f69-3ee9-491f-ac7b-82fd0ed15ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm\n",
    "\n",
    "import category_encoders as ce\n",
    "import catboost\n",
    "from sklearn import metrics\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../utils\")\n",
    "from metrics import compute_recall_at4, compute_normalized_gini, compute_amex_metric\n",
    "#from messaging import send_message\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdb87e8-2c27-477a-8a12-e83e09fa312c",
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b343d32b-8f96-48a2-8c98-9d1e56ed1e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics in catboost format\n",
    "class AmexMetric:\n",
    "    \n",
    "    def is_max_optimal(self):\n",
    "        return True\n",
    "\n",
    "    def evaluate(self, approxes, target, weight):    \n",
    "        assert len(approxes) == 1\n",
    "        assert len(target) == len(approxes[0])\n",
    "        scores = approxes[0]\n",
    "        target = target\n",
    "        return compute_amex_metric(target, scores), 1.\n",
    "\n",
    "    def get_final_error(self, error, weight):\n",
    "        return error\n",
    "\n",
    "class RecallAt4:\n",
    "    \n",
    "    def is_max_optimal(self):\n",
    "        return True\n",
    "\n",
    "    def evaluate(self, approxes, target, weight):\n",
    "        assert len(approxes) == 1\n",
    "        assert len(target) == len(approxes[0])\n",
    "        scores = np.array(approxes[0])\n",
    "        target = np.array(target)                                   \n",
    "        return compute_recall_at4(target, scores), 1.\n",
    "\n",
    "    def get_final_error(self, error, weight):\n",
    "        return error\n",
    "\n",
    "class NormGini:\n",
    "    \n",
    "    def is_max_optimal(self):\n",
    "        return True\n",
    "\n",
    "    def evaluate(self, approxes, target, weight):\n",
    "        assert len(approxes) == 1\n",
    "        assert len(target) == len(approxes[0])\n",
    "        scores = np.array(approxes[0])\n",
    "        target = np.array(target)                   \n",
    "        return compute_normalized_gini(target, scores), 1.\n",
    "\n",
    "    def get_final_error(self, error, weight):\n",
    "        return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a630192a-1a7f-4186-888c-5b15de5d7a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIG PARAMS\n",
    "N_REPEATS = 3\n",
    "DATASET_VERSION = \"05\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecb64f2-f960-419e-8b9a-24f31220bcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_PATH = Path(f\"../data/feat-selection\")\n",
    "\n",
    "if not OUT_PATH.exists():\n",
    "    OUT_PATH.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a656788-39ee-45c8-8a2a-d310c834997f",
   "metadata": {},
   "source": [
    "***\n",
    "## load and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a1a144-c091-4058-9211-c048c7374757",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_parquet(f\"../data/processed/dsv{DATASET_VERSION}/train.parquet\")\n",
    "train_labels = pd.read_csv(\"../data/raw/train_labels.csv\", index_col=\"customer_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cb212c-b4ba-4374-9c11-5cb4e4778bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78996f6-cbb9-4a46-9149-856084e44988",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_feats = train.columns.tolist()\n",
    "#categ_feats = [\n",
    "#    'B_30_first', 'B_38_first', 'D_114_first', 'D_116_first', 'D_117_first', \n",
    "#    'D_120_first', 'D_126_first', 'D_63_first', 'D_64_first', 'D_66_first', 'D_68_first',\n",
    "#    'B_30_last', 'B_38_last', 'D_114_last', 'D_116_last', 'D_117_last', \n",
    "#    'D_120_last', 'D_126_last', 'D_63_last', 'D_64_last', 'D_66_last', 'D_68_last',\n",
    "#]\n",
    "len(input_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7249dc7b-f858-4012-9c5c-b6a540f5f187",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.merge(train, train_labels, how=\"inner\", left_index=True, right_index=True)\n",
    "del train_labels\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f8f26d-3fec-4bd4-83ed-309056185802",
   "metadata": {},
   "source": [
    "***\n",
    "## model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3ab3ba-b698-4f23-b4f2-d16fb85e2585",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    'eval_metric':AmexMetric(),\n",
    "    'learning_rate': 0.05,\n",
    "    'nan_mode':'Min',\n",
    "    'random_seed': 2112,\n",
    "    'auto_class_weights': None,\n",
    "    'bootstrap_type': 'Bernoulli',\n",
    "    'depth': 5,\n",
    "    'rsm': 0.2,\n",
    "    'iterations': 3900,\n",
    "    'l2_leaf_reg': 8.017281499631434,\n",
    "    'min_data_in_leaf': 1600,\n",
    "    'random_strength': 7.69963242351621,\n",
    "    'subsample': 0.8500000000000001,\n",
    "    # early stopping\n",
    "    'early_stopping_rounds':300,\n",
    "    'use_best_model': True,\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6d0072-f117-4576-a4b0-659fa4c70651",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(dataframe: pd.DataFrame, n_folds: int = 5,) -> tuple:\n",
    "    \n",
    "    models = list()\n",
    "    oof_dfs = list()\n",
    "    \n",
    "    for fold in range(n_folds):\n",
    "        \n",
    "        print(f\" training model {fold+1}/{n_folds} \".center(100, \"#\"))\n",
    "        \n",
    "        train_df = dataframe.query(\"fold != @fold\").copy()\n",
    "        valid_df = dataframe.query(\"fold == @fold\").copy()\n",
    "                \n",
    "        train_dset = catboost.Pool(\n",
    "            data=train_df.loc[:,input_feats],\n",
    "            label=train_df.loc[:,\"target\"].values,\n",
    "            #cat_features=categ_feats,\n",
    "        )\n",
    "        valid_dset = catboost.Pool(\n",
    "            data=valid_df.loc[:,input_feats],\n",
    "            label=valid_df.loc[:,\"target\"].values,\n",
    "            #cat_features=categ_feats,\n",
    "        )\n",
    "        \n",
    "        model = catboost.CatBoostClassifier(**model_params)\n",
    "        model.fit(\n",
    "            train_dset,\n",
    "            eval_set=valid_dset,\n",
    "            verbose=50,\n",
    "        )\n",
    "                    \n",
    "        valid_df.loc[:,\"pred\"] = model.predict(valid_dset, prediction_type=\"Probability\")[:,1]\n",
    "        \n",
    "        models.append(model)\n",
    "        oof_dfs.append(valid_df)\n",
    "        del train_df,train_dset,valid_dset\n",
    "        gc.collect()\n",
    "    \n",
    "    return models,oof_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ad44c4-72c5-4d14-b7d9-b9d47af2e3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "all_models = list()\n",
    "all_oof_dfs = list()\n",
    "\n",
    "for repetition in range(1,N_REPEATS+1):\n",
    "\n",
    "    print(f\" repeated cross-validation step: {repetition+1}/{N_REPEATS} \".center(100, \"#\"))\n",
    "\n",
    "    folds = pd.read_csv(f'../data/processed/cv{repetition}.csv', index_col=\"customer_ID\")\n",
    "    _train = pd.merge(train, folds, how=\"inner\", left_index=True, right_index=True).reset_index(drop=True)\n",
    "    \n",
    "    tic = time.time()\n",
    "    models,oof_dfs = train_models(_train)\n",
    "    tac = time.time()\n",
    "    print(f\"Training time: {(tac-tic)/60} min.\")\n",
    "              \n",
    "    all_models.extend(models)\n",
    "    all_oof_dfs.extend(oof_dfs)\n",
    "              \n",
    "    del _train, folds; gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe74d94-7c5e-45c3-8424-2aaa2d35117b",
   "metadata": {},
   "source": [
    "***\n",
    "## computes LFC (loss function change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eee06af-4b3d-4f92-aa64-423d1507e28f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outputs = list()\n",
    "\n",
    "for model,oof_df in zip(all_models,all_oof_dfs):\n",
    "    oof_dset = catboost.Pool(\n",
    "        data = oof_df.loc[:,input_feats],\n",
    "        label = oof_df.loc[:,\"target\"].values,\n",
    "    )\n",
    "    out = model.get_feature_importance(\n",
    "        data = oof_dset,\n",
    "        type = \"LossFunctionChange\",\n",
    "        verbose=True,\n",
    "    )\n",
    "    outputs.append(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebe2a5e-87c4-4278-9154-307ac4a54cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_lfc = pd.DataFrame(outputs, columns=input_feats)\n",
    "result_lfc.to_csv(OUT_PATH/\"catb-lfc.csv\", index=False)\n",
    "result_lfc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d614cf4-d597-436b-b4a6-6d232c188652",
   "metadata": {},
   "source": [
    "***\n",
    "## computes SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7033a09d-7fc4-42e0-892f-9d20b0e3f839",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = list()\n",
    "\n",
    "for model,oof_df in zip(all_models,all_oof_dfs):  \n",
    "    oof_dset = catboost.Pool(\n",
    "        data = oof_df.loc[:,input_feats],\n",
    "        label = oof_df.loc[:,\"target\"].values,\n",
    "    )\n",
    "    out = model.get_feature_importance(\n",
    "        data = oof_dset,\n",
    "        type = \"ShapValues\",\n",
    "        verbose=True,\n",
    "    )\n",
    "    outputs.append(np.mean(np.abs(out[:,:-1]), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5271471-4188-43f2-b97e-bf1c2402eb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_shap = pd.DataFrame(outputs, columns=input_feats)\n",
    "results_shap.to_csv(OUT_PATH/\"catb-shap.csv\", index=False)\n",
    "results_shap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1460f1e1-367f-40ff-a82f-425a59699d91",
   "metadata": {},
   "source": [
    "***\n",
    "## computes PFI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1ebb72-9439-497d-8048-47d678753e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pfi(\n",
    "        model:catboost.core.CatBoostClassifier,\n",
    "        dataframe:pd.DataFrame, \n",
    "        features:list, \n",
    "        target:str\n",
    "    ):\n",
    "    dataframe = dataframe.copy()\n",
    "    \n",
    "    # calculates base score\n",
    "    preds = model.predict(dataframe[features], prediction_type=\"Probability\")[:,1]\n",
    "    target = dataframe[target].values\n",
    "    BASE_SCORE = compute_amex_metric(target, preds)\n",
    "\n",
    "    output = OrderedDict()\n",
    "    output[\"base_score\"] = BASE_SCORE\n",
    "\n",
    "    # calculates pfi for each feature\n",
    "    for col in tqdm(features):\n",
    "        raw_values = dataframe[col].copy()\n",
    "        index = np.random.permutation(dataframe.index.values)\n",
    "        dataframe[col] = dataframe.loc[index, col].values\n",
    "        preds = model.predict(dataframe[features], prediction_type=\"Probability\")[:,1]\n",
    "        score = compute_amex_metric(target, preds)\n",
    "        pfi = (BASE_SCORE - score)\n",
    "        output[col] = pfi\n",
    "        # rollback the permutation\n",
    "        dataframe[col] = raw_values\n",
    "        del raw_values\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f308c45-76f4-4017-b99a-18427dbace8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = list()\n",
    "\n",
    "for model,oof_df in zip(all_models,all_oof_dfs):\n",
    "    out = compute_pfi(\n",
    "        model=model,\n",
    "        dataframe=oof_df,\n",
    "        features=input_feats,\n",
    "        target=\"target\",\n",
    "    )\n",
    "    outputs.append(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad7f421-cbbb-4fca-af05-784c1d21e82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_pfi = pd.DataFrame(outputs)\n",
    "result_pfi.to_csv(OUT_PATH/\"catb-pfi.csv\", index=False)\n",
    "result_pfi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a4228c-8895-461e-9fe1-93aafee32166",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
