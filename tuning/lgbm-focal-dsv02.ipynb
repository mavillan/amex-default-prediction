{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "import category_encoders as ce\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics\n",
    "from scipy import special\n",
    "from scipy import optimize\n",
    "\n",
    "import optuna\n",
    "from optuna.visualization import (\n",
    "    plot_contour\n",
    "    , plot_edf\n",
    "    , plot_intermediate_values\n",
    "    , plot_optimization_history\n",
    "    , plot_parallel_coordinate\n",
    "    , plot_param_importances\n",
    "    , plot_slice\n",
    ")\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../utils\")\n",
    "from metrics import compute_recall_at4, compute_normalized_gini, compute_amex_metric\n",
    "\n",
    "np.random.seed(2112)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## load and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ../data/processed/dsv02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_parquet(\"../data/processed/dsv02/train.parquet\")\n",
    "train_labels = pd.read_csv(\"../data/raw/train_labels.csv\", index_col=\"customer_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_feats = train.columns.tolist()\n",
    "categ_feats = [\n",
    "    'B_30_first', 'B_38_first', 'D_114_first', 'D_116_first', 'D_117_first', \n",
    "    'D_120_first', 'D_126_first', 'D_63_first', 'D_64_first', 'D_66_first', 'D_68_first',\n",
    "    'B_30_last', 'B_38_last', 'D_114_last', 'D_116_last', 'D_117_last', \n",
    "    'D_120_last', 'D_126_last', 'D_63_last', 'D_64_last', 'D_66_last', 'D_68_last',\n",
    "]\n",
    "len(input_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.merge(train, train_labels, how=\"inner\", left_index=True, right_index=True)\n",
    "train = train.reset_index()\n",
    "\n",
    "del train_labels\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## loss tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=3, random_state=2112, shuffle=True)\n",
    "skf_split = list(skf.split(train, train[\"target\"].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    'metric': 'None',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'max_bin': 511,\n",
    "    'bin_construct_sample_cnt': 100000000,\n",
    "    'bagging_freq': 1,\n",
    "    'bagging_fraction': 0.95,\n",
    "    'feature_fraction': 0.15,\n",
    "    'lambda_l1': 10.352308845012756,\n",
    "    'lambda_l2': 1.569788743184169,\n",
    "    'min_data_in_leaf': 2000,\n",
    "    'path_smooth': 30.4965047619009,\n",
    "    'seed': 2112,\n",
    "    'force_col_wise': True,\n",
    "    'feature_pre_filter': False,\n",
    "    'verbosity': -1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss:\n",
    "\n",
    "    def __init__(self, gamma, alpha=None):\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def at(self, y):\n",
    "        if self.alpha is None:\n",
    "            return np.ones_like(y)\n",
    "        return np.where(y, self.alpha, 1 - self.alpha)\n",
    "\n",
    "    def pt(self, y, p):\n",
    "        p = np.clip(p, 1e-15, 1 - 1e-15)\n",
    "        return np.where(y, p, 1 - p)\n",
    "\n",
    "    def __call__(self, y_true, y_pred):\n",
    "        at = self.at(y_true)\n",
    "        pt = self.pt(y_true, y_pred)\n",
    "        return -at * (1 - pt) ** self.gamma * np.log(pt)\n",
    "\n",
    "    def grad(self, y_true, y_pred):\n",
    "        y = 2 * y_true - 1  # {0, 1} -> {-1, 1}\n",
    "        at = self.at(y_true)\n",
    "        pt = self.pt(y_true, y_pred)\n",
    "        g = self.gamma\n",
    "        return at * y * (1 - pt) ** g * (g * pt * np.log(pt) + pt - 1)\n",
    "\n",
    "    def hess(self, y_true, y_pred):\n",
    "        y = 2 * y_true - 1  # {0, 1} -> {-1, 1}\n",
    "        at = self.at(y_true)\n",
    "        pt = self.pt(y_true, y_pred)\n",
    "        g = self.gamma\n",
    "\n",
    "        u = at * y * (1 - pt) ** g\n",
    "        du = -at * y * g * (1 - pt) ** (g - 1)\n",
    "        v = g * pt * np.log(pt) + pt - 1\n",
    "        dv = g * np.log(pt) + g + 1\n",
    "\n",
    "        return (du * v + u * dv) * y * (pt * (1 - pt))\n",
    "\n",
    "    def compute_init_score(self, y_true):\n",
    "        res = optimize.minimize_scalar(\n",
    "            lambda p: self(y_true, p).sum(),\n",
    "            bounds=(0, 1),\n",
    "            method='bounded'\n",
    "        )\n",
    "        p = res.x\n",
    "        self.init_score = np.log(p / (1 - p))\n",
    "\n",
    "    def lgb_obj(self, preds, train_data):\n",
    "        y = train_data.get_label()\n",
    "        p = special.expit(preds)\n",
    "        return self.grad(y, p), self.hess(y, p)\n",
    "\n",
    "    def lgb_eval(self, preds, train_data):\n",
    "        y = train_data.get_label()\n",
    "        p = special.expit(preds)\n",
    "        is_higher_better = False\n",
    "        return 'focal_loss', self(y, p).mean(), is_higher_better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(\n",
    "        dataframe:pd.DataFrame, \n",
    "        split:list, \n",
    "        model_params:dict, \n",
    "        fl_params:dict,\n",
    "        use_init_score:bool,\n",
    "        num_boost_round:int,\n",
    "    ) -> pd.DataFrame:\n",
    "    \n",
    "    # dataframe to store the oof predictions\n",
    "    oof = dataframe[[\"target\"]].copy()\n",
    "    oof[\"pred\"] = -1\n",
    "\n",
    "    for train_idx,valid_idx in split:\n",
    "        \n",
    "        train_df = dataframe.loc[train_idx,:]\n",
    "        valid_df = dataframe.loc[valid_idx,:]\n",
    "        \n",
    "        fl = FocalLoss(**fl_params)\n",
    "        if use_init_score:\n",
    "            fl.compute_init_score(train_df.loc[:,\"target\"].values)\n",
    "            init_score = np.full_like(train_df.loc[:,\"target\"].values, fl.init_score)\n",
    "        else:\n",
    "            init_score = None\n",
    "        \n",
    "        train_dset = lgb.Dataset(\n",
    "            data=train_df[input_feats],\n",
    "            label=train_df[\"target\"].values,\n",
    "            categorical_feature=categ_feats,\n",
    "            free_raw_data=True,\n",
    "            init_score=init_score\n",
    "        )        \n",
    "        model = lgb.train(\n",
    "            params=model_params,\n",
    "            train_set=train_dset,\n",
    "            fobj=fl.lgb_obj,\n",
    "            num_boost_round=num_boost_round,\n",
    "        )\n",
    "        \n",
    "        if use_init_score:\n",
    "            predictions = special.expit(model.predict(valid_df[input_feats]) + fl.init_score)\n",
    "        else:\n",
    "            predictions = special.expit(model.predict(valid_df[input_feats]))\n",
    "        oof.loc[valid_idx,\"pred\"] = predictions\n",
    "            \n",
    "        del train_dset,model\n",
    "        gc.collect()\n",
    "    \n",
    "    return oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    if trial.suggest_categorical(\"use_alpha\", [False, True]):\n",
    "        alpha = trial.suggest_float('alpha', 0, 1)\n",
    "    else:\n",
    "        alpha = None \n",
    "    gamma = trial.suggest_float('gamma', 0, 20)\n",
    "    fl_params = dict(alpha=alpha, gamma=gamma)\n",
    "    \n",
    "    use_init_score = trial.suggest_categorical(\"use_init_score\", [False, True])\n",
    "    num_boost_round = trial.suggest_int('num_boost_round', 1000, 3000, 50)\n",
    "\n",
    "    oof = train_models(\n",
    "        train, \n",
    "        skf_split, \n",
    "        model_params, \n",
    "        fl_params, \n",
    "        use_init_score,\n",
    "        num_boost_round,\n",
    "    )\n",
    "    metric = compute_amex_metric(oof.target.values, oof.pred.values)\n",
    "    return metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_optimize = True\n",
    "\n",
    "study = optuna.create_study(\n",
    "    study_name=\"lgbm-focal-dsv02\",\n",
    "    direction='maximize',\n",
    "    storage='sqlite:///lgbm-focal-dsv02.db',\n",
    "    load_if_exists=True,\n",
    ")\n",
    "\n",
    "if do_optimize:\n",
    "    study.optimize(\n",
    "        objective, \n",
    "        n_trials=1000, \n",
    "        timeout=86400, # 1-days\n",
    "        n_jobs=1, \n",
    "        gc_after_trial=True,\n",
    "    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.trials_dataframe().sort_values(\"value\", ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_slice(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_edf(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_parallel_coordinate(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(study.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
