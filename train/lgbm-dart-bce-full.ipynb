{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn import metrics\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../utils\")\n",
    "from metrics import compute_recall_at4, compute_normalized_gini, compute_amex_metric\n",
    "#from messaging import send_message\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# metrics in lgbm format\n",
    "\n",
    "def metric_recall_at4(y_pred: np.ndarray, data: lgb.Dataset):\n",
    "    y_true = data.get_label()\n",
    "    return 'recall_at4', compute_recall_at4(y_true, y_pred), True\n",
    "\n",
    "def metric_normalized_gini(y_pred: np.ndarray, data: lgb.Dataset):\n",
    "    y_true = data.get_label()\n",
    "    return 'norm_gini', compute_normalized_gini(y_true, y_pred), True\n",
    "\n",
    "def metric_amex(y_pred: np.ndarray, data: lgb.Dataset):\n",
    "    y_true = data.get_label()\n",
    "    return 'amex_metric', compute_amex_metric(y_true, y_pred), True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIG PARAMS\n",
    "SEEDS = [2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47]\n",
    "DATASET_VERSION = \"06\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OOF_PATH = Path(f\"../data/oof/lgbm-dart-bce-dsv{DATASET_VERSION}-full\")\n",
    "SUB_PATH = Path(f\"../data/subs/lgbm-dart-bce-dsv{DATASET_VERSION}-full\")\n",
    "ART_PATH = Path(f\"../artifacts/lgbm-dart-bce-dsv{DATASET_VERSION}-full\")\n",
    "\n",
    "if not OOF_PATH.exists():\n",
    "    OOF_PATH.mkdir(parents=True, exist_ok=True)\n",
    "if not SUB_PATH.exists():\n",
    "    SUB_PATH.mkdir(parents=True, exist_ok=True)\n",
    "if not ART_PATH.exists():\n",
    "    ART_PATH.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## load and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_parquet(f\"../data/processed/dsv{DATASET_VERSION}/train.parquet\")\n",
    "train_labels = pd.read_csv(\"../data/raw/train_labels.csv\", index_col=\"customer_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_feats = train.columns.tolist()\n",
    "len(input_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.merge(train, train_labels, how=\"inner\", left_index=True, right_index=True)\n",
    "del train_labels\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## model training\n",
    "\n",
    "train with repeated cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    'boosting': 'dart',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'None',\n",
    "    'num_iterations': 4350,\n",
    "    'num_leaves': 15,\n",
    "    'learning_rate': 0.05,\n",
    "    'max_bin': 63,\n",
    "    'bin_construct_sample_cnt': 100000000,\n",
    "    'bagging_freq': 1,\n",
    "    'bagging_fraction': 1.0,\n",
    "    'feature_fraction': 0.15,\n",
    "    'lambda_l1': 5.996099571922015,\n",
    "    'lambda_l2': 2.8900783163910697,\n",
    "    'min_data_in_leaf': 1000,\n",
    "    'path_smooth': 1.476306537276899,\n",
    "    'min_gain_to_split': 0.313937968985787,\n",
    "    'seed': 2112,\n",
    "    'force_col_wise': True,\n",
    "    'feature_pre_filter': True,\n",
    "    'verbosity': -1,\n",
    "    # dropout params\n",
    "    'drop_rate': 0.1,\n",
    "    'max_drop': 40,\n",
    "    'skip_drop': 0.7,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(dataframe:pd.DataFrame, model_params:dict) -> lgb.Booster:         \n",
    "    train_dset = lgb.Dataset(\n",
    "        data=dataframe.loc[:,input_feats],\n",
    "        label=dataframe.loc[:,\"target\"].values,\n",
    "        free_raw_data=True,\n",
    "    )\n",
    "    model = lgb.train(\n",
    "        params=model_params,\n",
    "        train_set=train_dset,\n",
    "    )\n",
    "    lgb.plot_importance(model, figsize=(8,15), importance_type=\"split\", max_num_features=30)\n",
    "    lgb.plot_importance(model, figsize=(8,15), importance_type=\"gain\", max_num_features=30)\n",
    "    plt.show()        \n",
    "\n",
    "    del train_dset\n",
    "    gc.collect()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "all_models = list()\n",
    "\n",
    "for it,seed in enumerate(SEEDS):\n",
    "    print(\"#\"*80)\n",
    "    print(f\" Training model {it+1} of {len(SEEDS)} \".center(80, \"#\"))\n",
    "    print(\"#\"*80)\n",
    "    \n",
    "    _model_params = dict(model_params)\n",
    "    _model_params[\"seed\"] = seed\n",
    "    \n",
    "    tic = time.time()\n",
    "    model = train_model(train, _model_params)\n",
    "    tac = time.time()\n",
    "    print(f\"Training time: {(tac-tic)/60} min.\")\n",
    "    \n",
    "    all_models.append(model)\n",
    "    \n",
    "# save models\n",
    "for seed,_model in zip(SEEDS,all_models):\n",
    "    _model.save_model(ART_PATH/f\"model-seed{str(seed).zfill(2)}.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "del train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## make predictions and submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = pd.read_parquet(f\"../data/processed/dsv{DATASET_VERSION}/test.parquet\")\n",
    "sub = pd.read_csv(\"../data/raw/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "all_preds = list()\n",
    "\n",
    "for seed,model in zip(SEEDS,all_models):\n",
    "    if \"prediction\" in sub.columns:\n",
    "        sub.drop(\"prediction\", axis=1, inplace=True)\n",
    "    if \"prediction\" in test.columns:\n",
    "        test.drop(\"prediction\", axis=1, inplace=True)\n",
    "        \n",
    "    preds = model.predict(test[input_feats])\n",
    "    all_preds.append(preds)\n",
    "       \n",
    "    test[\"prediction\"] = preds\n",
    "    sub[\"prediction\"] = test.loc[sub.customer_ID.values,\"prediction\"].values\n",
    "    assert sub.prediction.isna().sum() == 0\n",
    "    sub.to_csv(SUB_PATH/f\"submission-seed{str(seed).zfill(2)}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# predict using all the trained models\n",
    "if \"prediction\" in sub.columns:\n",
    "    sub.drop(\"prediction\", axis=1, inplace=True)\n",
    "if \"prediction\" in test.columns:\n",
    "    test.drop(\"prediction\", axis=1, inplace=True)\n",
    "\n",
    "test[\"prediction\"] = np.mean(all_preds, axis=0)\n",
    "sub[\"prediction\"] = test.loc[sub.customer_ID.values,\"prediction\"].values\n",
    "assert sub.prediction.isna().sum() == 0\n",
    "sub.to_csv(SUB_PATH/f\"submission-all.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
